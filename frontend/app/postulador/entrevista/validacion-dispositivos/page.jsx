'use client';

import { useEffect, useRef, useState } from 'react';
import { useRouter, useSearchParams } from 'next/navigation';
import { useStream } from '../../../../context/StreamContext';
import { mostrarTerminosYCondiciones } from '../../../components/modals/TerminosEntrevista';

export default function ValidacionDispositivos() {
  const router = useRouter();
  const { setCameraStream } = useStream();

  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const searchParams = useSearchParams();
  const token = searchParams.get('token');

  const [camReady, setCamReady] = useState(false);
  const [micReady, setMicReady] = useState(false);
  const [camaras, setCamaras] = useState([]);
  const [microfonos, setMicrofonos] = useState([]);
  const [selectedCam, setSelectedCam] = useState('');
  const [selectedMic, setSelectedMic] = useState('');
  const micAudioElement = useRef(null);

  // üì¶ Guardar la referencia para liberar el micr√≥fono al desmontar
  const currentMicStream = useRef(null);

  // üîç Detectar dispositivos disponibles
  useEffect(() => {
    const listarDispositivos = async () => {
      const devices = await navigator.mediaDevices.enumerateDevices();
      const videoInputs = devices.filter((d) => d.kind === 'videoinput');
      const audioInputs = devices.filter((d) => d.kind === 'audioinput');

      setCamaras(videoInputs);
      setMicrofonos(audioInputs);
      if (videoInputs[0]) setSelectedCam(videoInputs[0].deviceId);
      if (audioInputs[0]) setSelectedMic(audioInputs[0].deviceId);
    };

    listarDispositivos();
  }, []);

  // üé• Acceder a la c√°mara y mantener el stream activo (NO detenerlo en cleanup)
  useEffect(() => {
    const accederCamara = async () => {
      if (!selectedCam) return;

      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { deviceId: selectedCam },
        });

        if (videoRef.current) videoRef.current.srcObject = stream;
        setCameraStream(stream);         // Pasar al context
        window.copiaCamara = stream;     // Global (opcional)
        setCamReady(true);
      } catch (err) {
        console.warn('No se pudo acceder a la c√°mara:', err);
        setCamReady(false);
      }
    };

    accederCamara();
  }, [selectedCam]);

  // üéôÔ∏è Acceder al micr√≥fono y visualizar en canvas
// üéôÔ∏è Acceder al micr√≥fono y visualizar en canvas
useEffect(() => {
  const accederMicrofono = async () => {
    if (!selectedMic) return;

    // üîá Detener audio anterior si existe
    if (micAudioElement.current) {
      micAudioElement.current.pause();
      micAudioElement.current.srcObject = null;
      micAudioElement.current = null;
    }

    if (currentMicStream.current) {
      currentMicStream.current.getTracks().forEach((track) => track.stop());
      currentMicStream.current = null;
    }

    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: { deviceId: selectedMic },
      });

      currentMicStream.current = stream;

      // üîä Loopback actualizado
      micAudioElement.current = new Audio();
      micAudioElement.current.srcObject = stream;
      micAudioElement.current.play().catch(() => {}); // evitar AbortError
      setMicReady(true);

      // üéõÔ∏è Visualizaci√≥n en canvas
      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const source = audioContext.createMediaStreamSource(stream);
      const analyser = audioContext.createAnalyser();
      source.connect(analyser);
      analyser.fftSize = 256;

      const bufferLength = analyser.fftSize;
      const dataArray = new Uint8Array(bufferLength);
      const canvas = canvasRef.current;
      const ctx = canvas.getContext('2d');

      const draw = () => {
        requestAnimationFrame(draw);
        analyser.getByteTimeDomainData(dataArray);

        ctx.fillStyle = '#2B2C3F';
        ctx.fillRect(0, 0, canvas.width, canvas.height);
        ctx.lineWidth = 2;
        ctx.strokeStyle = '#3BDCF6';
        ctx.beginPath();

        const sliceWidth = canvas.width / bufferLength;
        let x = 0;

        for (let i = 0; i < bufferLength; i++) {
          const v = dataArray[i] / 128.0;
          const y = (v * canvas.height) / 2;
          if (i === 0) ctx.moveTo(x, y);
          else ctx.lineTo(x, y);
          x += sliceWidth;
        }

        ctx.lineTo(canvas.width, canvas.height / 2);
        ctx.stroke();
      };

      draw();
    } catch (err) {
      console.warn('No se pudo acceder al micr√≥fono:', err);
      setMicReady(false);
    }
  };

  accederMicrofono();
}, [selectedMic]);


  // üßº Limpiar solo micr√≥fono
  useEffect(() => {
    return () => {
      if (currentMicStream.current) {
        currentMicStream.current.getTracks().forEach((track) => track.stop());
        currentMicStream.current = null;
      }
      if (micAudioElement.current) {
        micAudioElement.current.pause();
        micAudioElement.current.srcObject = null;
      }
    };
  }, []);

  return (
    <div className="min-h-screen bg-[#0A0A23] text-white px-6 py-10 flex flex-col items-center">
      <h2 className="text-2xl font-bold mb-8">Verifica tu c√°mara, micr√≥fono y comparte pantalla</h2>

      <div className="grid grid-cols-1 md:grid-cols-2 gap-8 w-full max-w-5xl mb-6">
        {/* C√°mara */}
        <div className="bg-[#1D1E33] p-6 rounded-lg shadow-md">
          <label className="block mb-2 text-sm text-gray-300">Selecciona tu c√°mara</label>
          <select
            className="w-full mb-4 text-sm p-2 bg-[#2B2C3F] rounded text-white"
            value={selectedCam}
            onChange={(e) => setSelectedCam(e.target.value)}
          >
            {camaras.map((cam) => (
              <option key={cam.deviceId} value={cam.deviceId}>
                {cam.label || 'C√°mara sin nombre'}
              </option>
            ))}
          </select>
          <div className="bg-black rounded overflow-hidden flex justify-center">
            <video ref={videoRef} autoPlay muted className="rounded max-w-full h-auto" />
          </div>
          <p className="mt-2 text-sm">{camReady ? 'C√°mara detectada ‚úîÔ∏è' : 'C√°mara no detectada ‚ùå'}</p>
        </div>

        {/* Micr√≥fono */}
        <div className="bg-[#1D1E33] p-6 rounded-lg shadow-md">
          <label className="block mb-2 text-sm text-gray-300">Selecciona tu micr√≥fono</label>
          <select
            className="w-full mb-2 text-sm p-2 bg-[#2B2C3F] rounded text-white"
            value={selectedMic}
            onChange={(e) => setSelectedMic(e.target.value)}
          >
            {microfonos.map((mic) => (
              <option key={mic.deviceId} value={mic.deviceId}>
                {mic.label || 'Micr√≥fono sin nombre'}
              </option>
            ))}
          </select>

          <label className="text-sm mb-1 block">Habla para probar tu micr√≥fono.</label>
          <div className="mt-2 mb-4 rounded overflow-hidden">
            <canvas ref={canvasRef} width={400} height={80} className="w-full rounded bg-[#2B2C3F]" />
          </div>

          <p className="mt-2 text-sm">{micReady ? 'Micr√≥fono detectado ‚úîÔ∏è' : 'Micr√≥fono no detectado ‚ùå'}</p>
        </div>
      </div>

      <button
        onClick={() => mostrarTerminosYCondiciones(router, token)}
        disabled={!camReady || !micReady}
        className={`px-6 py-3 text-sm rounded-full font-semibold ${
          camReady && micReady
            ? 'bg-white text-black hover:bg-gray-200'
            : 'bg-gray-500 text-gray-300 cursor-not-allowed'
        }`}
      >
        Iniciar entrevista
      </button>

      <p className="text-xs text-gray-400 text-center mt-6 max-w-3xl">
        Al continuar, acepta que los resultados de esta entrevista asistida por IA pueden incluir grabaciones y capturas autom√°ticas.
      </p>
    </div>
  );
}
